#import sas
library(klaR)
library(InformationValue)
data(GermanCredit)


numvector<-sapply(GermanCredit,is.numeric)
data<-cbind(GermanCredit[,numvector,drop=FALSE],GermanCredit['credit_risk'])
#name   = c("tc_memberid","jf_memberid","isOverdue")

Dlq_tag= as.factor(ifelse(data[,"credit_risk"]=="good",0,1))
data1 = cbind(data[,!names(data) %in% 'credit_risk'],Dlq_tag)
train<-sample(nrow(data1),size=nrow(data1)*0.7,replace = F)

training_set<-data1[train,]   #提取样本数据集
test_set<-data1[-train,]   #提取测试数据集
case_weights<-ifelse(training_set$Dlq_tag==0,1,1) #weight



#寻找最优参数mtry，即指定节点中用于二叉树的最佳变量个数
library("randomForest")
n<-length(names(training_set))     #计算数据集中自变量个数，等同n=ncol(training_set)
rate=1     #设置模型误判率向量初始值

for(i in 1:(n-1)){
  set.seed(1234)
  rf_train<-randomForest( Dlq_tag~., data=training_set,mtry=i, importance=TRUE, ntree=500, na.action = na.omit)
  rate[i]<-mean(rf_train$err.rate)   #计算基于OOB数据的模型误判率均值
  #print(rf_train)    
}

rate     #展示所有模型误判率的均值
plot(rate)


#寻找最佳参数ntree，即指定随机森林所包含的最佳决策树数目
set.seed(100)
rf_train<-randomForest(training_set$Dlq_tag~.,data=training_set,mtry=6,ntree=500)
plot(rf_train)    #绘制模型误差与决策树数量关系图  
legend(800,0.02,"Dlq_tag=0",cex=0.9,bty="n")    
legend(800,0.0245,"total",cex=0.09,bty="n") 



#随机森林模型搭建
#importance设定是否输出因变量在模型中的重要性，如果移除某个变量，模型方差增加的比例是它判断变量重要性的标准之一；
#proximity参数用于设定是否计算模型的临近矩阵；
#ntree用于设定随机森林的树数
set.seed(100)
rf_train<-randomForest(Dlq_tag~.,
                       data=training_set,  mtry=6,ntree=300,importance=TRUE,proximity=TRUE)   

rf_train


#输出变量重要性:分别从精确度递减和均方误差递减的角度来衡量重要程度
importance<-importance(rf_train) 
#write.csv(importance,file="E:/模型搭建/importance.csv",row.names=T,quote=F)
barplot(rf_train$importance[,1],   main="输入变量重要性测度指标柱形图")
box()


#提取随机森林模型中以准确率递减方法得到维度重要性值。type=2为基尼系数方法
#importance(rf_train,type=2)
importance(rf_train,type=1)
varImpPlot(x=rf_train,sort=TRUE,n.var=nrow(rf_train$importance),main="输入变量重要性测度散点图")



print(rf_train)    #展示随机森林模型简要信息
hist(treesize(rf_train))   #展示随机森林模型中每棵决策树的节点数
max(treesize(rf_train));min(treesize(rf_train))

#展示数据集在二维情况下各类别的具体分布情况
#MDSplot(rf_train, training_set$Dlq_tag ,k=1,palette=rep(1,4),pch=20) 
MDSplot(rf_train, training_set$Dlq_tag)
MDSplot(rf_train, training_set[,4])

#检测
pred<-predict(rf_train,newdata=test_set)  
pred_out_1<-predict(object=rf_train,newdata=test_set,type="prob")  #输出概率
table <- table(pred,test_set$Dlq_tag) 
table

#预测准确率
sum(diag(table))/sum(table)  
plot(margin(rf_train,  test_set$Dlq_tag),main="观测值被判断正确的概率图")








#############################################
#1:randomForest()函数用于构建随机森林模型
randomForest(formula, data=NULL, ..., subset, na.action=na.fail)
randomForest(x, y=NULL, xtest=NULL, ytest=NULL, ntree=500,
             mtry=if (!is.null(y) && !is.factor(y))
               max(floor(ncol(x)/3), 1) else floor(sqrt(ncol(x))),
             replace=TRUE, classwt=NULL, cutoff, strata,
             sampsize = if (replace) nrow(x) else ceiling(.632*nrow(x)),
             nodesize = if (!is.null(y) && !is.factor(y)) 5 else 1,
             maxnodes = NULL,
             importance=FALSE, localImp=FALSE, nPerm=1,
             proximity, oob.prox=proximity,
             norm.votes=TRUE, do.trace=FALSE,
             keep.forest=!is.null(y) && is.null(xtest), corr.bias=FALSE,
             keep.inbag=FALSE, ...)



# formula指定模型的公式形式，类似于y~x1+x2+x3…;
# data指定分析的数据集；
# subset以向量的形式确定样本数据集；
# na.action指定数据集中缺失值的处理方法，默认为na.fail，即不允许出现缺失值，也可以指定为na.omit，即删除缺失样本；
# x指定模型的解释变量，可以是矩阵，也可以是数据框；
# y指定模型的因变量，可以是离散的因子，也可以是连续的数值，分别对应于随机森林的分类模型和预测模型。这里需要说明的是，如果不指定y值，则随机森林将是一个无监督的模型；
# xtest和ytest用于预测的测试集；
# ntree指定随机森林所包含的决策树数目，默认为500；
# mtry指定节点中用于二叉树的变量个数，默认情况下数据集变量个数的二次方根（分类模型）或三分之一（预测模型）。一般是需要进行人为的逐次挑选，确定最佳的m值；
# replace指定Bootstrap随机抽样的方式，默认为有放回的抽样
# classwt指定分类水平的权重，对于回归模型，该参数无效；
# strata为因子向量，用于分层抽样；
# sampsize用于指定样本容量，一般与参数strata联合使用，指定分层抽样中层的样本量；
# nodesize指定决策树节点的最小个数，默认情况下，判别模型为1，回归模型为5；
# maxnodes指定决策树节点的最大个数；
# importance逻辑参数，是否计算各个变量在模型中的重要性，默认不计算，该参数主要结合importance()函数使用；
# proximity逻辑参数，是否计算模型的临近矩阵，主要结合MDSplot()函数使用；
# oob.prox是否基于OOB数据计算临近矩阵；
# norm.votes显示投票格式，默认以百分比的形式展示投票结果，也可以采用绝对数的形式；
# do.trace是否输出更详细的随机森林模型运行过程，默认不输出；
# keep.forest是否保留模型的输出对象，对于给定xtest值后，默认将不保留算法的运算结果;



#2:importance()函数用于计算模型变量的重要性
importance(x, type=NULL, class="NULL", scale=TRUE, ...)

 
# x为randomForest对象；
# type可以是1，也可以是2，用于判别计算变量重要性的方法，1表示使用精度平均较少值作为度量标准；2表示采用节点不纯度的平均减少值最为度量标准。值越大说明变量的重要性越强；
# scale默认对变量的重要性值进行标准化。



#3:MDSplot()函数用于实现随机森林的可视化
MDSplot(rf, fac, k=2, palette=NULL, pch=20, ...)


# rf为randomForest对象，需要说明的是，在构建随机森林模型时必须指定计算临近矩阵，即设置proximity参数为TRUE；
# fac指定随机森林模型中所使用到的因子向量（因变量）；
# palette指定所绘图形中各个类别的颜色；
# pch指定所绘图形中各个类别形状；
# 还可以通过R自带的plot函数绘制随机森林决策树的数目与模型误差的折线图



#4:rfImpute()函数可为存在缺失值的数据集进行插补（随机森林法），得到最优的样本拟合值

rfImpute(x, y, iter=5, ntree=300, ...)
rfImpute(x, data, ..., subset)


# x为存在缺失值的数据集；
# y为因变量，不可以存在缺失情况；
# iter指定插值过程中迭代次数；
# ntree指定每次迭代生成的随机森林中决策树数量；
# subset以向量的形式指定样本集。



#5:treesize()函数用于计算随机森林中每棵树的节点个数

treesize(x, terminal=TRUE)

# x为randomForest对象；
# terminal指定计算节点数目的方式，默认只计算每棵树的根节点，设置为FALSE时将计算所有节点（根节点+叶节点）。
# 一般treesize()函数生成的结果用于绘制直方图，方面查看随机森林中树的节点分布情况。






















